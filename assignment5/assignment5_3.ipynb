{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 717, which is longer than the specified 600\n",
      "Created a chunk of size 608, which is longer than the specified 600\n",
      "Created a chunk of size 642, which is longer than the specified 600\n",
      "Created a chunk of size 1444, which is longer than the specified 600\n",
      "Created a chunk of size 1251, which is longer than the specified 600\n",
      "Created a chunk of size 1012, which is longer than the specified 600\n",
      "Created a chunk of size 2313, which is longer than the specified 600\n",
      "Created a chunk of size 1458, which is longer than the specified 600\n",
      "Created a chunk of size 1673, which is longer than the specified 600\n",
      "Created a chunk of size 742, which is longer than the specified 600\n",
      "Created a chunk of size 669, which is longer than the specified 600\n",
      "Created a chunk of size 906, which is longer than the specified 600\n",
      "Created a chunk of size 703, which is longer than the specified 600\n",
      "Created a chunk of size 1137, which is longer than the specified 600\n",
      "Created a chunk of size 1559, which is longer than the specified 600\n",
      "Created a chunk of size 1200, which is longer than the specified 600\n",
      "Created a chunk of size 859, which is longer than the specified 600\n",
      "Created a chunk of size 845, which is longer than the specified 600\n",
      "Created a chunk of size 716, which is longer than the specified 600\n",
      "Created a chunk of size 840, which is longer than the specified 600\n",
      "Created a chunk of size 1042, which is longer than the specified 600\n",
      "Created a chunk of size 652, which is longer than the specified 600\n",
      "Created a chunk of size 985, which is longer than the specified 600\n",
      "Created a chunk of size 859, which is longer than the specified 600\n",
      "Created a chunk of size 659, which is longer than the specified 600\n",
      "Created a chunk of size 693, which is longer than the specified 600\n",
      "Created a chunk of size 817, which is longer than the specified 600\n",
      "Created a chunk of size 655, which is longer than the specified 600\n",
      "Created a chunk of size 1345, which is longer than the specified 600\n",
      "Created a chunk of size 1339, which is longer than the specified 600\n",
      "Created a chunk of size 1288, which is longer than the specified 600\n",
      "Created a chunk of size 1014, which is longer than the specified 600\n",
      "Created a chunk of size 617, which is longer than the specified 600\n",
      "Created a chunk of size 617, which is longer than the specified 600\n",
      "Created a chunk of size 1178, which is longer than the specified 600\n",
      "Created a chunk of size 2247, which is longer than the specified 600\n",
      "Created a chunk of size 1728, which is longer than the specified 600\n",
      "Created a chunk of size 841, which is longer than the specified 600\n",
      "Created a chunk of size 743, which is longer than the specified 600\n",
      "Created a chunk of size 694, which is longer than the specified 600\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "cache_dir = LocalFileStore('./cache/')\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader('./document.txt')\n",
    "documents = loader.load_and_split(text_splitter=splitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vb/g6q1dzv560x2fpy8l9jkvt4w0000gn/T/ipykernel_21758/2472924487.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  OpenAIEmbeddings(),\n"
     ]
    }
   ],
   "source": [
    "embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    OpenAIEmbeddings(),\n",
    "    cache_dir\n",
    ")\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vb/g6q1dzv560x2fpy8l9jkvt4w0000gn/T/ipykernel_21758/3618950543.py:7: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(\"Where does Winston live?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Winston is currently being held in a windowless building where he has been imprisoned and interrogated. The specific location is not explicitly mentioned, but it is described as being underground, with cells below ground level and the room where he was interrogated by O'Brien high up near the roof.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the context provided, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain.run(\"Is Aaronson guilty?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-nomard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
